---
title: AI SDK Integration
description: Seamlessly integrate Promptsmith with Vercel AI SDK
---

# Vercel AI SDK Integration

Promptsmith provides first-class integration with [Vercel AI SDK](https://sdk.vercel.ai/), allowing you to use your prompts and tools with minimal setup.

## Why Vercel AI SDK?

Vercel AI SDK is a powerful framework for building AI applications with:

- **Multi-provider support** - OpenAI, Anthropic, Google, and more
- **Tool calling** - Automatic tool execution with streaming
- **Type safety** - Full TypeScript support
- **React hooks** - Easy integration in React applications

Promptsmith makes it even better with structured prompts and type-safe tools.

## Installation

Install both Promptsmith and the AI SDK:

```bash npm
npm install @promptsmith/core ai @ai-sdk/openai zod
```

```bash pnpm
pnpm add @promptsmith/core ai @ai-sdk/openai zod
```

```bash bun
bun add @promptsmith/core ai @ai-sdk/openai zod
```

You can also install providers for Anthropic, Google, etc.:

```bash
npm install @ai-sdk/anthropic @ai-sdk/google
```

## Quick Start

The simplest way to use Promptsmith with AI SDK is with the `.toAiSdk()` method:

```typescript
import { createPromptBuilder } from "@promptsmith/core";
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

const builder = createPromptBuilder()
  .identity("You are a helpful weather assistant")
  .tool({
    name: "get_weather",
    description: "Get current weather for a location",
    schema: z.object({
      location: z.string().describe("City name"),
    }),
    execute: async ({ location }) => {
      // Your weather API call
      return { temp: 72, condition: "sunny" };
    },
  });

// Use with spread operator
const response = await generateText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(),
  prompt: "What's the weather in Paris?",
  maxSteps: 5,
});

console.log(response.text);
```

That's it! The AI SDK will automatically:

1. Send the system prompt to the model
2. Let the model know about available tools
3. Execute tools when the model requests them
4. Stream results back

## The `toAiSdk()` Method

The `.toAiSdk()` method returns an object with two properties:

```typescript
const config = builder.toAiSdk();

// Returns:
{
  system: string,           // The complete system prompt
  tools: Record<string, {   // Tools in AI SDK format
    description: string;
    parameters: ZodType;
    execute?: Function;
  }>
}
```

You can spread this directly into AI SDK function calls:

```typescript
const response = await generateText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(), // Expands to system + tools
  prompt: userMessage,
  maxSteps: 5,
});
```

Or destructure if you prefer:

```typescript
const { system, tools } = builder.toAiSdk();

const response = await generateText({
  model: openai("gpt-4"),
  system,
  tools,
  prompt: userMessage,
});
```

## Text Generation

Generate text responses with automatic tool calling:

```typescript
import { createPromptBuilder } from "@promptsmith/core";
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

const assistant = createPromptBuilder()
  .identity("You are a helpful research assistant")
  .tool({
    name: "search_papers",
    description: "Search academic papers",
    schema: z.object({
      query: z.string(),
      field: z.enum(["cs", "physics", "biology"]).optional(),
    }),
    execute: async ({ query, field }) => {
      // Search implementation
      return [
        { title: "Paper 1", authors: "Smith et al." },
        { title: "Paper 2", authors: "Jones et al." },
      ];
    },
  });

const result = await generateText({
  model: openai("gpt-4-turbo"),
  ...assistant.toAiSdk(),
  prompt: "Find papers about quantum computing",
  maxSteps: 5, // Allow multiple tool calls
});

console.log(result.text);
console.log(result.toolCalls); // Array of tool calls made
console.log(result.toolResults); // Results from tool executions
```

## Streaming Responses

Stream responses as they're generated:

```typescript
import { streamText } from "ai";

const assistant = createPromptBuilder()
  .identity("You are a creative writing assistant")
  .tool({
    name: "get_writing_prompt",
    description: "Get a random writing prompt",
    schema: z.object({
      genre: z.enum(["scifi", "fantasy", "mystery"]),
    }),
    execute: async ({ genre }) => {
      return { prompt: `A ${genre} story about...` };
    },
  });

const result = await streamText({
  model: openai("gpt-4"),
  ...assistant.toAiSdk(),
  prompt: "Give me a sci-fi writing prompt",
});

// Stream the response
for await (const chunk of result.textStream) {
  process.stdout.write(chunk);
}
```

## React Integration

Use Promptsmith with AI SDK's React hooks:

```tsx
"use client";

import { createPromptBuilder } from "@promptsmith/core";
import { useChat } from "ai/react";
import { z } from "zod";

const weatherAssistant = createPromptBuilder()
  .identity("You are a weather assistant")
  .tool({
    name: "get_weather",
    description: "Get weather for a location",
    schema: z.object({
      location: z.string(),
    }),
    execute: async ({ location }) => {
      const res = await fetch(`/api/weather?location=${location}`);
      return res.json();
    },
  });

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: "/api/chat",
    // Send configuration to API
    body: {
      config: weatherAssistant.toAiSdk(),
    },
  });

  return (
    <div>
      {messages.map((m) => (
        <div key={m.id}>
          <strong>{m.role}:</strong> {m.content}
        </div>
      ))}

      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}
```

API Route:

```typescript
// app/api/chat/route.ts
import { streamText } from "ai";
import { openai } from "@ai-sdk/openai";

export async function POST(req: Request) {
  const { messages, config } = await req.json();

  const result = await streamText({
    model: openai("gpt-4"),
    ...config, // Use the Promptsmith config
    messages,
  });

  return result.toDataStreamResponse();
}
```

## Multiple Models

Promptsmith works with any AI SDK provider:

### OpenAI

```typescript
import { openai } from "@ai-sdk/openai";

const result = await generateText({
  model: openai("gpt-4-turbo"),
  ...builder.toAiSdk(),
  prompt: userMessage,
});
```

### Anthropic Claude

```typescript
import { anthropic } from "@ai-sdk/anthropic";

const result = await generateText({
  model: anthropic("claude-3-opus-20240229"),
  ...builder.toAiSdk(),
  prompt: userMessage,
});
```

### Google Gemini

```typescript
import { google } from "@ai-sdk/google";

const result = await generateText({
  model: google("gemini-pro"),
  ...builder.toAiSdk(),
  prompt: userMessage,
});
```

### Multiple Providers

Switch providers dynamically:

```typescript
const builder = createPromptBuilder()
  .identity("You are a helpful assistant")
  .tool({ name: "search", ... });

const config = builder.toAiSdk();

// Use with different providers
const openaiResult = await generateText({
  model: openai('gpt-4'),
  ...config,
  prompt: "Hello"
});

const claudeResult = await generateText({
  model: anthropic('claude-3-opus-20240229'),
  ...config,
  prompt: "Hello"
});
```

## Manual Tool Management

If you want more control, use `.toAiSdkTools()` to get just the tools:

```typescript
const builder = createPromptBuilder()
  .identity("You are an assistant")
  .tool({ name: "tool1", ... })
  .tool({ name: "tool2", ... });

const systemPrompt = builder.build();
const tools = builder.toAiSdkTools();

// Use separately
const result = await generateText({
  model: openai('gpt-4'),
  system: systemPrompt,
  tools: tools,
  prompt: userMessage
});
```

This is useful when you want to:

- Modify the system prompt before using it
- Filter or transform tools
- Mix Promptsmith tools with other tools

## Advanced Patterns

### Conditional Tools

Enable tools based on user permissions:

```typescript
function createAssistant(userRole: "admin" | "user") {
  const builder = createPromptBuilder()
    .identity("You are a support assistant")
    .tool({
      name: "get_info",
      description: "Get general information",
      schema: z.object({ query: z.string() }),
      execute: async ({ query }) => fetchInfo(query),
    });

  // Admin-only tools
  if (userRole === "admin") {
    builder.tool({
      name: "delete_account",
      description: "Delete a user account (admin only)",
      schema: z.object({ userId: z.string() }),
      execute: async ({ userId }) => deleteUser(userId),
    });
  }

  return builder.toAiSdk();
}

// Use with the appropriate role
const { system, tools } = createAssistant(currentUser.role);
```

### Tool Result Processing

Process tool results before sending to the AI:

```typescript
const result = await generateText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(),
  prompt: "Search for quantum computing papers",
  maxSteps: 5,
  onToolResult: ({ tool, result }) => {
    console.log(`Tool ${tool} returned:`, result);

    // You can modify the result here
    return {
      ...result,
      metadata: { timestamp: Date.now() },
    };
  },
});
```

### Streaming with Tool Calls

Handle tool calls during streaming:

```typescript
const result = await streamText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(),
  prompt: "What's the weather?",
  onToolCall: ({ tool, args }) => {
    console.log(`Calling tool: ${tool} with args:`, args);
  },
});

for await (const chunk of result.fullStream) {
  if (chunk.type === "tool-call") {
    console.log("Tool call:", chunk.toolName, chunk.args);
  } else if (chunk.type === "tool-result") {
    console.log("Tool result:", chunk.result);
  } else if (chunk.type === "text-delta") {
    process.stdout.write(chunk.textDelta);
  }
}
```

### Error Handling

Handle tool execution errors gracefully:

```typescript
const builder = createPromptBuilder()
  .identity("You are an assistant")
  .tool({
    name: "risky_operation",
    description: "Perform a risky operation",
    schema: z.object({ input: z.string() }),
    execute: async ({ input }) => {
      try {
        return await riskyApiCall(input);
      } catch (error) {
        // Return error info for AI to handle
        return {
          error: true,
          message: error.message,
          suggestion: "Please try again with different input",
        };
      }
    },
  });

const result = await generateText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(),
  prompt: "Do the risky thing",
});

// AI will see the error and can respond appropriately
```

## Complete Example

A full-featured AI assistant with multiple tools:

```typescript
import { createPromptBuilder } from "@promptsmith/core";
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

// Create the assistant
const assistant = createPromptBuilder()
  .identity("You are a helpful e-commerce assistant")
  .capabilities([
    "Search and recommend products",
    "Check inventory and pricing",
    "Process orders and track shipments",
  ])
  .tool({
    name: "search_products",
    description: "Search the product catalog",
    schema: z.object({
      query: z.string().describe("Search query"),
      category: z.string().optional().describe("Product category"),
      maxPrice: z.number().optional().describe("Maximum price"),
    }),
    execute: async ({ query, category, maxPrice }) => {
      return await searchProducts(query, category, maxPrice);
    },
  })
  .tool({
    name: "check_inventory",
    description: "Check if a product is in stock",
    schema: z.object({
      productId: z.string().describe("Product ID"),
    }),
    execute: async ({ productId }) => {
      return await checkInventory(productId);
    },
  })
  .tool({
    name: "get_price",
    description: "Get current price for a product",
    schema: z.object({
      productId: z.string().describe("Product ID"),
    }),
    execute: async ({ productId }) => {
      return await getPrice(productId);
    },
  })
  .constraint("must", "Always check inventory before recommending products")
  .constraint("must", "Confirm prices before stating them")
  .constraint("should", "Suggest alternatives if product is out of stock")
  .withTone("Be helpful and enthusiastic about products");

// Use the assistant
async function chat(userMessage: string) {
  const result = await generateText({
    model: openai("gpt-4-turbo"),
    ...assistant.toAiSdk(),
    prompt: userMessage,
    maxSteps: 5,
  });

  console.log("Response:", result.text);
  console.log("Tools used:", result.toolCalls?.length ?? 0);

  return result;
}

// Example usage
await chat("I'm looking for a laptop under $1000");
await chat("Is the MacBook Pro in stock?");
await chat("What's the current price?");
```

## Best Practices

### 1. Use maxSteps

Allow the AI to make multiple tool calls:

```typescript
const result = await generateText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(),
  prompt: userMessage,
  maxSteps: 5, // Allow up to 5 tool calls
});
```

### 2. Handle Long Operations

For long-running tools, provide progress updates:

```typescript
builder.tool({
  name: "generate_report",
  description: "Generate a comprehensive report (takes 30-60 seconds)",
  schema: z.object({ type: z.string() }),
  execute: async ({ type }) => {
    // Start the job
    const jobId = await startReportGeneration(type);

    // Return immediately with job ID
    return {
      status: "processing",
      jobId,
      message: "Report generation started. Check back in 60 seconds.",
      checkStatusUrl: `/api/reports/${jobId}/status`,
    };
  },
});
```

### 3. Validate in Execute

Add runtime validation in addition to schema validation:

```typescript
builder.tool({
  name: "transfer_money",
  description: "Transfer money between accounts",
  schema: z.object({
    from: z.string(),
    to: z.string(),
    amount: z.number(),
  }),
  execute: async ({ from, to, amount }) => {
    // Additional validation
    if (amount <= 0) {
      return { error: "Amount must be positive" };
    }

    if (from === to) {
      return { error: "Cannot transfer to same account" };
    }

    // Check balance
    const balance = await getBalance(from);
    if (balance < amount) {
      return { error: "Insufficient funds" };
    }

    // Proceed with transfer
    return await transferMoney(from, to, amount);
  },
});
```

### 4. Log Tool Usage

Track which tools are being used:

```typescript
const result = await generateText({
  model: openai("gpt-4"),
  ...builder.toAiSdk(),
  prompt: userMessage,
  onToolCall: ({ tool, args }) => {
    // Log to analytics
    analytics.track("tool_used", {
      tool,
      args,
      timestamp: Date.now(),
    });
  },
});
```

## Next Steps

<Cards>
  <Card
    title="Vercel AI SDK Docs"
    href="https://sdk.vercel.ai/docs"
    description="Official AI SDK documentation"
  />
  <Card
    title="Tools Guide"
    href="/docs/tools"
    description="Learn more about defining tools"
  />
  <Card
    title="Builder API"
    href="/docs/builder-api"
    description="Complete API reference"
  />
</Cards>
